{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53f7eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a372bd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d68dc1c",
   "metadata": {},
   "source": [
    "### a) Create a new Spark Session with new SparkConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7785b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "config = SparkConf().setMaster(\"local[4]\").setAppName(\"PySpark Assignment\")\n",
    "sc = SparkContext(conf=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e6c1f6",
   "metadata": {},
   "source": [
    "### b) Create new instance of Spark SQL session and define new DataFrame using sales_data_sample.csv dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ac6a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"AssignmentSession\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef486796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.8</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySpark Assignment</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa289e06cc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b003527",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data = spark.read.csv('file:///home/hadoop/Downloads/sales_data_sample.csv', \n",
    "                            header=True,\n",
    "                            inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e12860a",
   "metadata": {},
   "source": [
    "### c) Find the shape of DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "142bbbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 2823\n",
      "Number of cols: 25\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows:\", sales_data.count())\n",
    "print(\"Number of cols:\", len(sales_data.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1777535c",
   "metadata": {},
   "source": [
    "### d) Find the Summary of DataFrame for all numerical data columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35fd3010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructField(ORDERNUMBER,IntegerType,true),\n",
       " StructField(QUANTITYORDERED,IntegerType,true),\n",
       " StructField(PRICEEACH,DoubleType,true),\n",
       " StructField(ORDERLINENUMBER,IntegerType,true),\n",
       " StructField(SALES,DoubleType,true),\n",
       " StructField(ORDERDATE,StringType,true),\n",
       " StructField(STATUS,StringType,true),\n",
       " StructField(QTR_ID,IntegerType,true),\n",
       " StructField(MONTH_ID,IntegerType,true),\n",
       " StructField(YEAR_ID,IntegerType,true),\n",
       " StructField(PRODUCTLINE,StringType,true),\n",
       " StructField(MSRP,IntegerType,true),\n",
       " StructField(PRODUCTCODE,StringType,true),\n",
       " StructField(CUSTOMERNAME,StringType,true),\n",
       " StructField(PHONE,StringType,true),\n",
       " StructField(ADDRESSLINE1,StringType,true),\n",
       " StructField(ADDRESSLINE2,StringType,true),\n",
       " StructField(CITY,StringType,true),\n",
       " StructField(STATE,StringType,true),\n",
       " StructField(POSTALCODE,StringType,true),\n",
       " StructField(COUNTRY,StringType,true),\n",
       " StructField(TERRITORY,StringType,true),\n",
       " StructField(CONTACTLASTNAME,StringType,true),\n",
       " StructField(CONTACTFIRSTNAME,StringType,true),\n",
       " StructField(DEALSIZE,StringType,true)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_data.schema.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4920726",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ORDERNUMBER',\n",
       " 'QUANTITYORDERED',\n",
       " 'PRICEEACH',\n",
       " 'ORDERLINENUMBER',\n",
       " 'SALES',\n",
       " 'QTR_ID',\n",
       " 'MONTH_ID',\n",
       " 'YEAR_ID',\n",
       " 'MSRP']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType, LongType, ShortType, ByteType, FloatType, DoubleType\n",
    "\n",
    "numerical_types = (IntegerType, LongType, ShortType, ByteType, FloatType, DoubleType)\n",
    "\n",
    "numerical_columns = [field.name for field in sales_data.schema.fields if isinstance(field.dataType, tuple(numerical_types))]\n",
    "\n",
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "520c75dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|summary|       ORDERNUMBER|  QUANTITYORDERED|         PRICEEACH|  ORDERLINENUMBER|             SALES|            QTR_ID|          MONTH_ID|           YEAR_ID|              MSRP|\n",
      "+-------+------------------+-----------------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|  count|              2823|             2823|              2823|             2823|              2823|              2823|              2823|              2823|              2823|\n",
      "|   mean|10258.725115125753|35.09280906836698| 83.65854410201929|6.466170740347148|  3553.88907190932|2.7176762309599716|7.0924548352816155|2003.8150903294368|100.71555083244775|\n",
      "| stddev|  92.0854775957196| 9.74144273706958|20.174276527840536| 4.22584096469094|1841.8651057401842| 1.203878088001756| 3.656633307661765|0.6996701541300869| 40.18791167720266|\n",
      "|    min|             10100|                6|             26.88|                1|            482.13|                 1|                 1|              2003|                33|\n",
      "|    max|             10425|               97|             100.0|               18|           14082.8|                 4|                12|              2005|               214|\n",
      "+-------+------------------+-----------------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_data.select(numerical_columns).describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f20bd2c",
   "metadata": {},
   "source": [
    "### e) Identify and handle missing or null values in the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "002df213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+---------+---------------+-----+---------+------+------+--------+-------+-----------+----+-----------+------------+-----+------------+------------+----+-----+----------+-------+---------+---------------+----------------+--------+\n",
      "|ORDERNUMBER|QUANTITYORDERED|PRICEEACH|ORDERLINENUMBER|SALES|ORDERDATE|STATUS|QTR_ID|MONTH_ID|YEAR_ID|PRODUCTLINE|MSRP|PRODUCTCODE|CUSTOMERNAME|PHONE|ADDRESSLINE1|ADDRESSLINE2|CITY|STATE|POSTALCODE|COUNTRY|TERRITORY|CONTACTLASTNAME|CONTACTFIRSTNAME|DEALSIZE|\n",
      "+-----------+---------------+---------+---------------+-----+---------+------+------+--------+-------+-----------+----+-----------+------------+-----+------------+------------+----+-----+----------+-------+---------+---------------+----------------+--------+\n",
      "|          0|              0|        0|              0|    0|        0|     0|     0|       0|      0|          0|   0|          0|           0|    0|           0|        2521|   0| 1486|        76|      0|        0|              0|               0|       0|\n",
      "+-----------+---------------+---------+---------------+-----+---------+------+------+--------+-------+-----------+----+-----------+------------+-----+------------+------------+----+-----+----------+-------+---------+---------------+----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "null_counts = sales_data.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in sales_data.columns])\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e9a72fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|ADDRESSLINE2|\n",
      "+------------+\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|     Level 3|\n",
      "|   Suite 101|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ADDRESSLINE2\n",
    "#STATE\n",
    "#POSTALCODE\n",
    "sales_data.select(['ADDRESSLINE2']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a62782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_sales_data = sales_data.fillna({'ADDRESSLINE2': 'NA', 'STATE': 'NA', 'POSTALCODE': 'NA'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bf669d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+---------+---------------+-----+---------+------+------+--------+-------+-----------+----+-----------+------------+-----+------------+------------+----+-----+----------+-------+---------+---------------+----------------+--------+\n",
      "|ORDERNUMBER|QUANTITYORDERED|PRICEEACH|ORDERLINENUMBER|SALES|ORDERDATE|STATUS|QTR_ID|MONTH_ID|YEAR_ID|PRODUCTLINE|MSRP|PRODUCTCODE|CUSTOMERNAME|PHONE|ADDRESSLINE1|ADDRESSLINE2|CITY|STATE|POSTALCODE|COUNTRY|TERRITORY|CONTACTLASTNAME|CONTACTFIRSTNAME|DEALSIZE|\n",
      "+-----------+---------------+---------+---------------+-----+---------+------+------+--------+-------+-----------+----+-----------+------------+-----+------------+------------+----+-----+----------+-------+---------+---------------+----------------+--------+\n",
      "|          0|              0|        0|              0|    0|        0|     0|     0|       0|      0|          0|   0|          0|           0|    0|           0|           0|   0|    0|         0|      0|        0|              0|               0|       0|\n",
      "+-----------+---------------+---------+---------------+-----+---------+------+------+--------+-------+-----------+----+-----------+------------+-----+------------+------------+----+-----+----------+-------+---------+---------------+----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_sales_data.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in sales_data.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4a6114",
   "metadata": {},
   "source": [
    "### f) Calculate the total revenue generated per country by combining the columns QUANTITYORDERED and PRICEEACH using Spark DataFrame operations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10ec0588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+---------+---------------+-------+---------------+-------+------+--------+-------+-----------+----+-----------+--------------------+----------------+--------------------+------------+-------------+--------+----------+---------+---------+---------------+----------------+--------+------------------+\n",
      "|ORDERNUMBER|QUANTITYORDERED|PRICEEACH|ORDERLINENUMBER|  SALES|      ORDERDATE| STATUS|QTR_ID|MONTH_ID|YEAR_ID|PRODUCTLINE|MSRP|PRODUCTCODE|        CUSTOMERNAME|           PHONE|        ADDRESSLINE1|ADDRESSLINE2|         CITY|   STATE|POSTALCODE|  COUNTRY|TERRITORY|CONTACTLASTNAME|CONTACTFIRSTNAME|DEALSIZE|     TOTAL_REVENUE|\n",
      "+-----------+---------------+---------+---------------+-------+---------------+-------+------+--------+-------+-----------+----+-----------+--------------------+----------------+--------------------+------------+-------------+--------+----------+---------+---------+---------------+----------------+--------+------------------+\n",
      "|      10107|             30|     95.7|              2| 2871.0| 2/24/2003 0:00|Shipped|     1|       2|   2003|Motorcycles|  95|   S10_1678|   Land of Toys Inc.|      2125557818|897 Long Airport ...|          NA|          NYC|      NY|     10022|      USA|       NA|             Yu|            Kwai|   Small|            2871.0|\n",
      "|      10121|             34|    81.35|              5| 2765.9|  5/7/2003 0:00|Shipped|     2|       5|   2003|Motorcycles|  95|   S10_1678|  Reims Collectables|      26.47.1555|  59 rue de l'Abbaye|          NA|        Reims|      NA|     51100|   France|     EMEA|        Henriot|            Paul|   Small|2765.8999999999996|\n",
      "|      10134|             41|    94.74|              2|3884.34|  7/1/2003 0:00|Shipped|     3|       7|   2003|Motorcycles|  95|   S10_1678|     Lyon Souveniers|+33 1 46 62 7555|27 rue du Colonel...|          NA|        Paris|      NA|     75508|   France|     EMEA|       Da Cunha|          Daniel|  Medium|3884.3399999999997|\n",
      "|      10145|             45|    83.26|              6| 3746.7| 8/25/2003 0:00|Shipped|     3|       8|   2003|Motorcycles|  95|   S10_1678|   Toys4GrownUps.com|      6265557265|  78934 Hillside Dr.|          NA|     Pasadena|      CA|     90003|      USA|       NA|          Young|           Julie|  Medium|3746.7000000000003|\n",
      "|      10159|             49|    100.0|             14|5205.27|10/10/2003 0:00|Shipped|     4|      10|   2003|Motorcycles|  95|   S10_1678|Corporate Gift Id...|      6505551386|     7734 Strong St.|          NA|San Francisco|      CA|        NA|      USA|       NA|          Brown|           Julie|  Medium|            4900.0|\n",
      "|      10168|             36|    96.66|              1|3479.76|10/28/2003 0:00|Shipped|     4|      10|   2003|Motorcycles|  95|   S10_1678|Technics Stores Inc.|      6505556809|   9408 Furth Circle|          NA|   Burlingame|      CA|     94217|      USA|       NA|         Hirano|            Juri|  Medium|3479.7599999999998|\n",
      "|      10180|             29|    86.13|              9|2497.77|11/11/2003 0:00|Shipped|     4|      11|   2003|Motorcycles|  95|   S10_1678|Daedalus Designs ...|      20.16.1555|184, chausse de T...|          NA|        Lille|      NA|     59000|   France|     EMEA|          Rance|         Martine|   Small|           2497.77|\n",
      "|      10188|             48|    100.0|              1|5512.32|11/18/2003 0:00|Shipped|     4|      11|   2003|Motorcycles|  95|   S10_1678|        Herkku Gifts|   +47 2267 3215|Drammen 121, PR 7...|          NA|       Bergen|      NA|    N 5804|   Norway|     EMEA|         Oeztan|          Veysel|  Medium|            4800.0|\n",
      "|      10201|             22|    98.57|              2|2168.54| 12/1/2003 0:00|Shipped|     4|      12|   2003|Motorcycles|  95|   S10_1678|     Mini Wheels Co.|      6505555787|5557 North Pendal...|          NA|San Francisco|      CA|        NA|      USA|       NA|         Murphy|           Julie|   Small|           2168.54|\n",
      "|      10211|             41|    100.0|             14|4708.44| 1/15/2004 0:00|Shipped|     1|       1|   2004|Motorcycles|  95|   S10_1678|    Auto Canal Petit|  (1) 47.55.6555|   25, rue Lauriston|          NA|        Paris|      NA|     75016|   France|     EMEA|        Perrier|       Dominique|  Medium|            4100.0|\n",
      "|      10223|             37|    100.0|              1|3965.66| 2/20/2004 0:00|Shipped|     1|       2|   2004|Motorcycles|  95|   S10_1678|Australian Collec...|    03 9520 4555|   636 St Kilda Road|     Level 3|    Melbourne|Victoria|      3004|Australia|     APAC|       Ferguson|           Peter|  Medium|            3700.0|\n",
      "|      10237|             23|    100.0|              7|2333.12|  4/5/2004 0:00|Shipped|     2|       4|   2004|Motorcycles|  95|   S10_1678|     Vitachrome Inc.|      2125551500|   2678 Kingston Rd.|   Suite 101|          NYC|      NY|     10022|      USA|       NA|          Frick|         Michael|   Small|            2300.0|\n",
      "|      10251|             28|    100.0|              2|3188.64| 5/18/2004 0:00|Shipped|     2|       5|   2004|Motorcycles|  95|   S10_1678|Tekni Collectable...|      2015559350|       7476 Moss Rd.|          NA|       Newark|      NJ|     94019|      USA|       NA|          Brown|         William|  Medium|            2800.0|\n",
      "|      10263|             34|    100.0|              2|3676.76| 6/28/2004 0:00|Shipped|     2|       6|   2004|Motorcycles|  95|   S10_1678|     Gift Depot Inc.|      2035552570| 25593 South Bay Ln.|          NA|  Bridgewater|      CT|     97562|      USA|       NA|           King|           Julie|  Medium|            3400.0|\n",
      "|      10275|             45|    92.83|              1|4177.35| 7/23/2004 0:00|Shipped|     3|       7|   2004|Motorcycles|  95|   S10_1678|   La Rochelle Gifts|      40.67.8555|67, rue des Cinqu...|          NA|       Nantes|      NA|     44000|   France|     EMEA|        Labrune|          Janine|  Medium|           4177.35|\n",
      "|      10285|             36|    100.0|              6|4099.68| 8/27/2004 0:00|Shipped|     3|       8|   2004|Motorcycles|  95|   S10_1678|Marta's Replicas Co.|      6175558555| 39323 Spinnaker Dr.|          NA|    Cambridge|      MA|     51247|      USA|       NA|      Hernandez|           Marta|  Medium|            3600.0|\n",
      "|      10299|             23|    100.0|              9|2597.39| 9/30/2004 0:00|Shipped|     3|       9|   2004|Motorcycles|  95|   S10_1678|Toys of Finland, Co.|     90-224 8555|       Keskuskatu 45|          NA|     Helsinki|      NA|     21240|  Finland|     EMEA|      Karttunen|           Matti|   Small|            2300.0|\n",
      "|      10309|             41|    100.0|              5|4394.38|10/15/2004 0:00|Shipped|     4|      10|   2004|Motorcycles|  95|   S10_1678|  Baane Mini Imports|      07-98 9555|Erling Skakkes ga...|          NA|      Stavern|      NA|      4110|   Norway|     EMEA|     Bergulfsen|           Jonas|  Medium|            4100.0|\n",
      "|      10318|             46|    94.74|              1|4358.04| 11/2/2004 0:00|Shipped|     4|      11|   2004|Motorcycles|  95|   S10_1678|Diecast Classics ...|      2155551555|    7586 Pompton St.|          NA|    Allentown|      PA|     70267|      USA|       NA|             Yu|           Kyung|  Medium|           4358.04|\n",
      "|      10329|             42|    100.0|              1|4396.14|11/15/2004 0:00|Shipped|     4|      11|   2004|Motorcycles|  95|   S10_1678|   Land of Toys Inc.|      2125557818|897 Long Airport ...|          NA|          NYC|      NY|     10022|      USA|       NA|             Yu|            Kwai|  Medium|            4200.0|\n",
      "+-----------+---------------+---------+---------------+-------+---------------+-------+------+--------+-------+-----------+----+-----------+--------------------+----------------+--------------------+------------+-------------+--------+----------+---------+---------+---------------+----------------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_sales_data = cleaned_sales_data.withColumn(\"TOTAL_REVENUE\", col(\"QUANTITYORDERED\") * col(\"PRICEEACH\"))\n",
    "cleaned_sales_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ee22892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|    COUNTRY|     TOTAL_REVENUE|\n",
      "+-----------+------------------+\n",
      "|        USA|2986425.2099999995|\n",
      "|      Spain|1021705.9700000002|\n",
      "|     France| 919257.8499999997|\n",
      "|  Australia|521598.45999999985|\n",
      "|         UK|413203.33999999997|\n",
      "|      Italy| 309402.8699999999|\n",
      "|    Finland|268714.70000000007|\n",
      "|     Norway| 246115.8000000001|\n",
      "|  Singapore| 227985.5000000001|\n",
      "|     Canada|193504.34000000003|\n",
      "|    Denmark|         192747.63|\n",
      "|    Germany|         178689.08|\n",
      "|     Sweden|174264.10000000006|\n",
      "|    Austria|172793.05000000002|\n",
      "|      Japan|153076.68999999994|\n",
      "|    Belgium|          94528.88|\n",
      "|Switzerland| 93344.90999999999|\n",
      "|Philippines| 80291.16999999998|\n",
      "|    Ireland|          43237.24|\n",
      "+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_sales_data.groupBy('COUNTRY').agg(sum('TOTAL_REVENUE').alias('TOTAL_REVENUE'))\\\n",
    ".orderBy('TOTAL_REVENUE', ascending=False).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873725c3",
   "metadata": {},
   "source": [
    "### g) Determine the top 5 products with the highest total sales revenue using Spark DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f9df290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|PRODUCTCODE|TOTAL_REVENUE|\n",
      "+-----------+-------------+\n",
      "|   S18_3232|    176026.63|\n",
      "|   S24_3856|    103489.89|\n",
      "|   S18_4600|     101835.0|\n",
      "|   S24_2300|      99600.0|\n",
      "|   S18_2238|      96300.0|\n",
      "+-----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_sales_data.groupBy('PRODUCTCODE').agg(sum('TOTAL_REVENUE').alias('TOTAL_REVENUE'))\\\n",
    ".orderBy('TOTAL_REVENUE', ascending=False).show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e535613",
   "metadata": {},
   "source": [
    "### h) Find the average order quantity for each product using groupBy and agg operations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2588f65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|PRODUCTCODE|           AVG_QTY|\n",
      "+-----------+------------------+\n",
      "|   S18_4600| 38.18518518518518|\n",
      "|   S18_1749| 36.45454545454545|\n",
      "|   S12_3891| 35.42307692307692|\n",
      "|   S18_2248| 33.77272727272727|\n",
      "|  S700_1138| 34.69230769230769|\n",
      "|   S32_1268|32.333333333333336|\n",
      "|   S12_1099|             33.52|\n",
      "|   S18_2795|30.346153846153847|\n",
      "|   S24_1937|             33.76|\n",
      "|   S32_3522| 35.44444444444444|\n",
      "|   S18_1097| 35.67857142857143|\n",
      "|   S18_1662| 36.15384615384615|\n",
      "|   S12_1666|34.714285714285715|\n",
      "|   S24_3969| 33.86363636363637|\n",
      "|   S24_1578| 35.80769230769231|\n",
      "|   S24_4048| 32.46153846153846|\n",
      "|   S18_3320| 34.96153846153846|\n",
      "|   S24_3816| 33.46153846153846|\n",
      "|   S18_3136|32.333333333333336|\n",
      "|   S32_2509|34.107142857142854|\n",
      "+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "cleaned_sales_data.groupBy('PRODUCTCODE').agg(avg('QUANTITYORDERED').alias('AVG_QTY')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3645012",
   "metadata": {},
   "source": [
    "### i) Using Spark DataFrame, filter orders where the SALES value exceeds 10,000 and sort the results by the ORDERDATE column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f268303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------------+\n",
      "|PRODUCTCODE|  SALES|          ORDERDATE|\n",
      "+-----------+-------+-------------------+\n",
      "|   S12_1108|11279.2|2003-06-03 00:00:00|\n",
      "|   S10_1949|10993.5|2003-09-19 00:00:00|\n",
      "|   S12_1108|10606.2|2004-05-05 00:00:00|\n",
      "|   S10_1949|10172.7|2004-10-11 00:00:00|\n",
      "|   S10_1949|11623.7|2004-10-21 00:00:00|\n",
      "|   S18_2325|12536.5|2004-11-04 00:00:00|\n",
      "|   S18_3320|11336.7|2004-11-18 00:00:00|\n",
      "|   S24_3151|10758.0|2004-11-23 00:00:00|\n",
      "|   S24_4278|10039.6|2005-02-03 00:00:00|\n",
      "|  S700_1691|10066.6|2005-03-03 00:00:00|\n",
      "|   S10_4698|11886.6|2005-04-08 00:00:00|\n",
      "|   S24_3856|11739.7|2005-04-14 00:00:00|\n",
      "|   S18_3685|10468.9|2005-04-15 00:00:00|\n",
      "|   S18_1749|14082.8|2005-04-22 00:00:00|\n",
      "|   S18_3232|11887.8|2005-05-03 00:00:00|\n",
      "|   S10_1949|12001.0|2005-05-31 00:00:00|\n",
      "+-----------+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, to_timestamp\n",
    "\n",
    "cleaned_sales_data.withColumn('ORDERDATE', to_timestamp(col('ORDERDATE'), 'M/d/yyyy H:mm'))\\\n",
    ".filter((col('SALES') > 10000))\\\n",
    ".orderBy('ORDERDATE')\\\n",
    ".select(['PRODUCTCODE', 'SALES', 'ORDERDATE']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99398c4",
   "metadata": {},
   "source": [
    "### j) Filter out rows where the STATUS is &#39;Cancelled&#39; and calculate the total sales from the remaining orders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2310837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|      TOTAL_SALES|\n",
      "+-----------------+\n",
      "|9838141.370000018|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_sales_data\\\n",
    ".filter(col('STATUS') != 'Cancelled')\\\n",
    ".agg(sum('SALES').alias('TOTAL_SALES'))\\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b38c1d",
   "metadata": {},
   "source": [
    "### k) Use Spark Data Frame transformations to derive the yearly sales for each customer (CUSTOMERNAME) based on the ORDERDATE column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8bf1bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|        CUSTOMERNAME|\n",
      "+--------------------+\n",
      "|      AV Stores, Co.|\n",
      "|        Alpha Cognac|\n",
      "|  Amica Models & Co.|\n",
      "|Anna's Decoration...|\n",
      "|   Atelier graphique|\n",
      "|Australian Collec...|\n",
      "|Australian Collec...|\n",
      "|Australian Gift N...|\n",
      "|  Auto Assoc. & Cie.|\n",
      "|    Auto Canal Petit|\n",
      "|Auto-Moto Classic...|\n",
      "|  Baane Mini Imports|\n",
      "|Bavarian Collecta...|\n",
      "|Blauer See Auto, Co.|\n",
      "|   Boards & Toys Co.|\n",
      "|         CAF Imports|\n",
      "|Cambridge Collect...|\n",
      "|Canadian Gift Exc...|\n",
      "|Classic Gift Idea...|\n",
      "|Classic Legends Inc.|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_sales_data.select(['CUSTOMERNAME']).distinct().orderBy('CUSTOMERNAME').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e26529d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+------------------+\n",
      "|        CUSTOMERNAME|YEAR|       TOTAL_SALES|\n",
      "+--------------------+----+------------------+\n",
      "|      AV Stores, Co.|2003| 51017.91999999999|\n",
      "|      AV Stores, Co.|2004|         106789.89|\n",
      "|        Alpha Cognac|2003| 55349.31999999999|\n",
      "|        Alpha Cognac|2005|15139.119999999999|\n",
      "|  Amica Models & Co.|2004| 94117.26000000002|\n",
      "|Anna's Decoration...|2003| 88983.70999999999|\n",
      "|Anna's Decoration...|2005|          65012.42|\n",
      "|   Atelier graphique|2003|           16560.3|\n",
      "|   Atelier graphique|2004|           7619.66|\n",
      "|Australian Collec...|2003|          37878.55|\n",
      "|Australian Collec...|2004|          12334.82|\n",
      "|Australian Collec...|2005|          14378.09|\n",
      "|Australian Collec...|2003|60135.840000000004|\n",
      "|Australian Collec...|2004|140859.56999999998|\n",
      "|Australian Gift N...|2003|37739.090000000004|\n",
      "|Australian Gift N...|2005|          21730.03|\n",
      "|  Auto Assoc. & Cie.|2004| 64834.32000000001|\n",
      "|    Auto Canal Petit|2004| 79103.85999999999|\n",
      "|    Auto Canal Petit|2005|           14066.8|\n",
      "|Auto-Moto Classic...|2003|           7277.35|\n",
      "+--------------------+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date, year, to_timestamp\n",
    "\n",
    "yearly_data = cleaned_sales_data.withColumn(\"YEAR\", year(to_timestamp(col(\"ORDERDATE\"), 'M/d/yyyy H:mm')))\n",
    "\n",
    "yearly_data.groupBy(['CUSTOMERNAME', 'YEAR'])\\\n",
    ".agg(sum('SALES').alias('TOTAL_SALES'))\\\n",
    ".orderBy(['CUSTOMERNAME','YEAR']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7c10f3",
   "metadata": {},
   "source": [
    "### l) Add a new column to the DataFrame that categorizes orders as High, Medium, or Low sales based on the SALES value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ae0d18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|  SALES|CATEGORY|\n",
      "+-------+--------+\n",
      "| 2871.0|  Medium|\n",
      "| 2765.9|  Medium|\n",
      "|3884.34|  Medium|\n",
      "| 3746.7|  Medium|\n",
      "|5205.27|    High|\n",
      "|3479.76|  Medium|\n",
      "|2497.77|  Medium|\n",
      "|5512.32|    High|\n",
      "|2168.54|     Low|\n",
      "|4708.44|    High|\n",
      "|3965.66|    High|\n",
      "|2333.12|     Low|\n",
      "|3188.64|  Medium|\n",
      "|3676.76|  Medium|\n",
      "|4177.35|    High|\n",
      "|4099.68|    High|\n",
      "|2597.39|  Medium|\n",
      "|4394.38|    High|\n",
      "|4358.04|    High|\n",
      "|4396.14|    High|\n",
      "|7737.93|    High|\n",
      "| 1451.0|     Low|\n",
      "| 733.11|     Low|\n",
      "|3207.12|  Medium|\n",
      "|2434.56|     Low|\n",
      "|7516.08|    High|\n",
      "|5404.62|    High|\n",
      "|7209.11|    High|\n",
      "|7329.06|    High|\n",
      "| 7374.1|    High|\n",
      "|10993.5|    High|\n",
      "|4860.24|    High|\n",
      "|8014.82|    High|\n",
      "|5372.57|    High|\n",
      "|7290.36|    High|\n",
      "|9064.89|    High|\n",
      "| 6075.3|    High|\n",
      "|6463.23|    High|\n",
      "|6120.34|    High|\n",
      "|7680.64|    High|\n",
      "|4905.39|    High|\n",
      "|8014.82|    High|\n",
      "|7136.19|    High|\n",
      "|10172.7|    High|\n",
      "|11623.7|    High|\n",
      "| 6000.4|    High|\n",
      "| 3003.0|  Medium|\n",
      "| 3944.7|    High|\n",
      "|5691.84|    High|\n",
      "|4514.92|    High|\n",
      "| 8254.8|    High|\n",
      "|2416.56|     Low|\n",
      "|4140.23|    High|\n",
      "|12001.0|    High|\n",
      "|3896.49|  Medium|\n",
      "|2793.86|  Medium|\n",
      "|3307.77|  Medium|\n",
      "|5192.95|    High|\n",
      "|5016.83|    High|\n",
      "|3660.93|  Medium|\n",
      "| 4695.6|    High|\n",
      "|3660.92|  Medium|\n",
      "|3025.92|  Medium|\n",
      "|3009.09|  Medium|\n",
      "|5422.39|    High|\n",
      "|2852.08|  Medium|\n",
      "|5756.52|    High|\n",
      "| 4472.0|    High|\n",
      "|2904.44|  Medium|\n",
      "|6484.59|    High|\n",
      "|3757.26|  Medium|\n",
      "|4043.96|    High|\n",
      "| 5566.5|    High|\n",
      "| 3176.0|  Medium|\n",
      "| 2756.8|  Medium|\n",
      "| 1329.9|     Low|\n",
      "|5288.01|    High|\n",
      "| 2225.5|     Low|\n",
      "| 5833.8|    High|\n",
      "|5887.35|    High|\n",
      "|6065.55|    High|\n",
      "|9264.86|    High|\n",
      "|7023.98|    High|\n",
      "|5176.38|    High|\n",
      "| 4132.7|    High|\n",
      "| 4183.0|    High|\n",
      "| 8892.9|    High|\n",
      "| 8714.7|    High|\n",
      "|8065.89|    High|\n",
      "| 6123.4|    High|\n",
      "|9774.03|    High|\n",
      "| 7023.9|    High|\n",
      "|7078.23|    High|\n",
      "|8336.94|    High|\n",
      "|6901.92|    High|\n",
      "|5438.07|    High|\n",
      "|6683.34|    High|\n",
      "| 4570.4|    High|\n",
      "|7667.14|    High|\n",
      "| 5868.2|    High|\n",
      "+-------+--------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "percentile_33, percentile_67 = cleaned_sales_data.approxQuantile(\"SALES\", [0.33, 0.67], 0.01)\n",
    "\n",
    "sales_data_with_category = cleaned_sales_data.withColumn(\n",
    "    \"CATEGORY\",\n",
    "    when(col(\"SALES\") > percentile_67, \"High\")\\\n",
    "    .when(col(\"SALES\") > percentile_33, \"Medium\")\n",
    "    .otherwise(\"Low\")\n",
    ")\n",
    "\n",
    "\n",
    "sales_data_with_category.select(['SALES', 'CATEGORY']).show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bc742a",
   "metadata": {},
   "source": [
    "### m) Assume , If you have another DataFrame with customer demographic data, how would you perform a join to compute the total sales per demographic group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bd29a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------+-------------+------------------+\n",
      "|COUNTRY|        CUSTOMERNAME|INCOME|       REGION|       TOTAL_SALES|\n",
      "+-------+--------------------+------+-------------+------------------+\n",
      "|    USA|Cambridge Collect...|310000|North America|          36163.62|\n",
      "|    USA|Corporate Gift Id...|331000|North America|149882.49999999997|\n",
      "|Belgium|          Petit Auto|160000|       Europe| 74972.51999999999|\n",
      "+-------+--------------------+------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "demographic_data = [\n",
    "    (\"Toms Spezialitten\", \"Germany\", 480000, \"Europe\"),\n",
    "    (\"Oulu Toy Supplies\", \"Finland\", 55000, \"Europe\"),\n",
    "    (\"Petit Auto\", \"Belgium\", 160000, \"Europe\"),\n",
    "    (\"Corporate Gift Ideas Co.\", \"USA\", 331000, \"North America\"),\n",
    "    (\"Cambridge Collectables Co.\", \"USA\", 310000, \"North America\"),\n",
    "    ]\n",
    "\n",
    "\n",
    "demographic_df = spark.createDataFrame(demographic_data, [\"CUSTOMERNAME\", \"COUNTRY\", \"INCOME\", \"REGION\"])\n",
    "\n",
    "joined_df = cleaned_sales_data.join(demographic_df, on=[\"CUSTOMERNAME\",'COUNTRY'], how=\"inner\")\n",
    "\n",
    "sales_by_country = joined_df.groupBy(\"COUNTRY\",\"CUSTOMERNAME\",'INCOME', 'REGION')\\\n",
    ".agg(sum(\"SALES\").alias(\"TOTAL_SALES\"))\n",
    "\n",
    "\n",
    "sales_by_country.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4318d2",
   "metadata": {},
   "source": [
    "### n) Can you implement a cumulative distribution function (CDF) over the SALES value for each CUSTOMERNAME? What insights can you gather from analyzing the CDF distribution for each customer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e356ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[ORDERNUMBER: int, QUANTITYORDERED: int, PRICEEACH: double, ORDERLINENUMBER: int, SALES: double, ORDERDATE: string, STATUS: string, QTR_ID: int, MONTH_ID: int, YEAR_ID: int, PRODUCTLINE: string, MSRP: int, PRODUCTCODE: string, CUSTOMERNAME: string, PHONE: string, ADDRESSLINE1: string, ADDRESSLINE2: string, CITY: string, STATE: string, POSTALCODE: string, COUNTRY: string, TERRITORY: string, CONTACTLASTNAME: string, CONTACTFIRSTNAME: string, DEALSIZE: string, TOTAL_REVENUE: double]>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_sales_data.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "303e9db4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+-------------------+\n",
      "|       CUSTOMERNAME|  SALES|                CDF|\n",
      "+-------------------+-------+-------------------+\n",
      "|Suominen Souveniers| 891.03|0.03333333333333333|\n",
      "|Suominen Souveniers| 1086.6|0.06666666666666667|\n",
      "|Suominen Souveniers|1103.76|                0.1|\n",
      "|Suominen Souveniers|1629.04|0.13333333333333333|\n",
      "|Suominen Souveniers| 1988.4|0.16666666666666666|\n",
      "|Suominen Souveniers|2140.11|                0.2|\n",
      "|Suominen Souveniers|2447.76|0.23333333333333334|\n",
      "|Suominen Souveniers|2632.89|0.26666666666666666|\n",
      "|Suominen Souveniers| 2773.8|                0.3|\n",
      "|Suominen Souveniers|2775.08| 0.3333333333333333|\n",
      "|Suominen Souveniers|2817.87|0.36666666666666664|\n",
      "|Suominen Souveniers|2851.84|                0.4|\n",
      "|Suominen Souveniers|2931.98|0.43333333333333335|\n",
      "|Suominen Souveniers|3128.65| 0.4666666666666667|\n",
      "|Suominen Souveniers|3288.82|                0.5|\n",
      "|Suominen Souveniers|3595.62| 0.5333333333333333|\n",
      "|Suominen Souveniers|3686.54| 0.5666666666666667|\n",
      "|Suominen Souveniers| 3784.8|                0.6|\n",
      "|Suominen Souveniers| 4068.7| 0.6333333333333333|\n",
      "|Suominen Souveniers|4142.64| 0.6666666666666666|\n",
      "+-------------------+-------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, rank\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import cume_dist\n",
    "import numpy as np\n",
    "\n",
    "window_w = Window.partitionBy(\"CUSTOMERNAME\").orderBy(\"SALES\")\n",
    "\n",
    "cdf_df = cleaned_sales_data.withColumn(\n",
    "    \"CDF\",\n",
    "    cume_dist().over(window_w)\n",
    ")\n",
    "\n",
    "cdf_df.select([\"CUSTOMERNAME\", \"SALES\", \"CDF\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12a1536",
   "metadata": {},
   "source": [
    "50 percentage of Suominen Souveniers sales is below 3288.82"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3dd039",
   "metadata": {},
   "source": [
    "20% of customers have total upto 2000, indicating low spending customers\\\n",
    "median value is around 4000, half of the customers have total sales below 4000\\\n",
    "after 8000 there are fewer high spending customers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6704ed2",
   "metadata": {},
   "source": [
    "### o) Write spark dataframe code to rank products by total revenue within each country (COUNTRY)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ff7fbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+----+------------------+\n",
      "|COUNTRY|PRODUCTCODE|RANK|     TOTAL_REVENUE|\n",
      "+-------+-----------+----+------------------+\n",
      "| Sweden|   S18_4600|   1|            9700.0|\n",
      "| Sweden|   S24_2300|   2|            9000.0|\n",
      "| Sweden|   S24_2011|   3|            7400.0|\n",
      "| Sweden|   S18_2949|   4|            7000.0|\n",
      "| Sweden|   S10_1949|   5|            6600.0|\n",
      "| Sweden|   S12_1099|   6|           5675.04|\n",
      "| Sweden|   S10_4962|   7|            5600.0|\n",
      "| Sweden|  S700_1138|   8| 5579.620000000001|\n",
      "| Sweden|   S12_3990|   9|           5319.32|\n",
      "| Sweden|   S12_3380|  10|            5309.5|\n",
      "| Sweden|   S24_3151|  11| 5113.049999999999|\n",
      "| Sweden|   S12_4675|  12|            4700.0|\n",
      "| Sweden|   S18_2319|  13|            4600.0|\n",
      "| Sweden|   S24_1578|  14|            4500.0|\n",
      "| Sweden|   S10_4757|  15|            4400.0|\n",
      "| Sweden|   S18_4522|  16|            4300.5|\n",
      "| Sweden|   S18_1662|  17|            4300.0|\n",
      "| Sweden|   S24_3816|  18|4276.9400000000005|\n",
      "| Sweden|   S18_1097|  19|            4100.0|\n",
      "| Sweden|   S12_1666|  19|            4100.0|\n",
      "+-------+-----------+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import dense_rank, desc\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "cleaned_sales_data\\\n",
    ".groupBy(['PRODUCTCODE', 'COUNTRY']).agg(sum(\"TOTAL_REVENUE\").alias(\"TOTAL_REVENUE\"))\\\n",
    ".withColumn('RANK', dense_rank().over(Window.partitionBy('COUNTRY').orderBy(desc('TOTAL_REVENUE'))))\\\n",
    ".select(['COUNTRY', 'PRODUCTCODE','RANK', 'TOTAL_REVENUE']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38a724f",
   "metadata": {},
   "source": [
    "### p) Calculate a running total of SALES for each customer and show the top 5 customers by this cumulative total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0dd13338",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+------------------+\n",
      "|       CUSTOMERNAME|  SALES|      RUNNINGTOTAL|\n",
      "+-------------------+-------+------------------+\n",
      "|Suominen Souveniers| 891.03|            891.03|\n",
      "|Suominen Souveniers| 1086.6|1977.6299999999999|\n",
      "|Suominen Souveniers|1103.76|           3081.39|\n",
      "|Suominen Souveniers|1629.04|           4710.43|\n",
      "|Suominen Souveniers| 1988.4|           6698.83|\n",
      "|Suominen Souveniers|2140.11|           8838.94|\n",
      "|Suominen Souveniers|2447.76|           11286.7|\n",
      "|Suominen Souveniers|2632.89|          13919.59|\n",
      "|Suominen Souveniers| 2773.8|          16693.39|\n",
      "|Suominen Souveniers|2775.08|          19468.47|\n",
      "|Suominen Souveniers|2817.87|          22286.34|\n",
      "|Suominen Souveniers|2851.84|          25138.18|\n",
      "|Suominen Souveniers|2931.98|          28070.16|\n",
      "|Suominen Souveniers|3128.65|          31198.81|\n",
      "|Suominen Souveniers|3288.82|34487.630000000005|\n",
      "|Suominen Souveniers|3595.62| 38083.25000000001|\n",
      "|Suominen Souveniers|3686.54| 41769.79000000001|\n",
      "|Suominen Souveniers| 3784.8| 45554.59000000001|\n",
      "|Suominen Souveniers| 4068.7| 49623.29000000001|\n",
      "|Suominen Souveniers|4142.64| 53765.93000000001|\n",
      "+-------------------+-------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w = Window.partitionBy('CUSTOMERNAME')\\\n",
    "  .orderBy('SALES')\\\n",
    "  .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "max_sales_df = cleaned_sales_data\\\n",
    ".withColumn('RUNNINGTOTAL', sum('SALES').over(w))\\\n",
    ".select(['CUSTOMERNAME', 'SALES', 'RUNNINGTOTAL']).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0e4ea2",
   "metadata": {},
   "source": [
    "### q) Find and handle Invalid and Outliers values in entire DataFrame. [Check for only continuous dataset]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84ddda70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[ORDERNUMBER: int, QUANTITYORDERED: int, PRICEEACH: double, ORDERLINENUMBER: int, SALES: double, ORDERDATE: string, STATUS: string, QTR_ID: int, MONTH_ID: int, YEAR_ID: int, PRODUCTLINE: string, MSRP: int, PRODUCTCODE: string, CUSTOMERNAME: string, PHONE: string, ADDRESSLINE1: string, ADDRESSLINE2: string, CITY: string, STATE: string, POSTALCODE: string, COUNTRY: string, TERRITORY: string, CONTACTLASTNAME: string, CONTACTFIRSTNAME: string, DEALSIZE: string, TOTAL_REVENUE: double]>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_sales_data.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92ec291f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SALES: 81\n",
      "MSRP: 28\n",
      "QUANTITYORDERED: 8\n",
      "PRICEEACH: 0\n",
      "+-----------+---------------+---------+---------------+-------+---------------+-------+------+--------+-------+-----------+----+-----------+--------------------+----------------+--------------------+------------+-------------+--------+----------+---------+---------+---------------+----------------+--------+------------------+\n",
      "|ORDERNUMBER|QUANTITYORDERED|PRICEEACH|ORDERLINENUMBER|  SALES|      ORDERDATE| STATUS|QTR_ID|MONTH_ID|YEAR_ID|PRODUCTLINE|MSRP|PRODUCTCODE|        CUSTOMERNAME|           PHONE|        ADDRESSLINE1|ADDRESSLINE2|         CITY|   STATE|POSTALCODE|  COUNTRY|TERRITORY|CONTACTLASTNAME|CONTACTFIRSTNAME|DEALSIZE|     TOTAL_REVENUE|\n",
      "+-----------+---------------+---------+---------------+-------+---------------+-------+------+--------+-------+-----------+----+-----------+--------------------+----------------+--------------------+------------+-------------+--------+----------+---------+---------+---------------+----------------+--------+------------------+\n",
      "|      10107|           30.0|     95.7|              2| 2871.0| 2/24/2003 0:00|Shipped|     1|       2|   2003|Motorcycles|95.0|   S10_1678|   Land of Toys Inc.|      2125557818|897 Long Airport ...|          NA|          NYC|      NY|     10022|      USA|       NA|             Yu|            Kwai|   Small|            2871.0|\n",
      "|      10121|           34.0|    81.35|              5| 2765.9|  5/7/2003 0:00|Shipped|     2|       5|   2003|Motorcycles|95.0|   S10_1678|  Reims Collectables|      26.47.1555|  59 rue de l'Abbaye|          NA|        Reims|      NA|     51100|   France|     EMEA|        Henriot|            Paul|   Small|2765.8999999999996|\n",
      "|      10134|           41.0|    94.74|              2|3884.34|  7/1/2003 0:00|Shipped|     3|       7|   2003|Motorcycles|95.0|   S10_1678|     Lyon Souveniers|+33 1 46 62 7555|27 rue du Colonel...|          NA|        Paris|      NA|     75508|   France|     EMEA|       Da Cunha|          Daniel|  Medium|3884.3399999999997|\n",
      "|      10145|           45.0|    83.26|              6| 3746.7| 8/25/2003 0:00|Shipped|     3|       8|   2003|Motorcycles|95.0|   S10_1678|   Toys4GrownUps.com|      6265557265|  78934 Hillside Dr.|          NA|     Pasadena|      CA|     90003|      USA|       NA|          Young|           Julie|  Medium|3746.7000000000003|\n",
      "|      10159|           49.0|    100.0|             14|5205.27|10/10/2003 0:00|Shipped|     4|      10|   2003|Motorcycles|95.0|   S10_1678|Corporate Gift Id...|      6505551386|     7734 Strong St.|          NA|San Francisco|      CA|        NA|      USA|       NA|          Brown|           Julie|  Medium|            4900.0|\n",
      "|      10168|           36.0|    96.66|              1|3479.76|10/28/2003 0:00|Shipped|     4|      10|   2003|Motorcycles|95.0|   S10_1678|Technics Stores Inc.|      6505556809|   9408 Furth Circle|          NA|   Burlingame|      CA|     94217|      USA|       NA|         Hirano|            Juri|  Medium|3479.7599999999998|\n",
      "|      10180|           29.0|    86.13|              9|2497.77|11/11/2003 0:00|Shipped|     4|      11|   2003|Motorcycles|95.0|   S10_1678|Daedalus Designs ...|      20.16.1555|184, chausse de T...|          NA|        Lille|      NA|     59000|   France|     EMEA|          Rance|         Martine|   Small|           2497.77|\n",
      "|      10188|           48.0|    100.0|              1|5512.32|11/18/2003 0:00|Shipped|     4|      11|   2003|Motorcycles|95.0|   S10_1678|        Herkku Gifts|   +47 2267 3215|Drammen 121, PR 7...|          NA|       Bergen|      NA|    N 5804|   Norway|     EMEA|         Oeztan|          Veysel|  Medium|            4800.0|\n",
      "|      10201|           22.0|    98.57|              2|2168.54| 12/1/2003 0:00|Shipped|     4|      12|   2003|Motorcycles|95.0|   S10_1678|     Mini Wheels Co.|      6505555787|5557 North Pendal...|          NA|San Francisco|      CA|        NA|      USA|       NA|         Murphy|           Julie|   Small|           2168.54|\n",
      "|      10211|           41.0|    100.0|             14|4708.44| 1/15/2004 0:00|Shipped|     1|       1|   2004|Motorcycles|95.0|   S10_1678|    Auto Canal Petit|  (1) 47.55.6555|   25, rue Lauriston|          NA|        Paris|      NA|     75016|   France|     EMEA|        Perrier|       Dominique|  Medium|            4100.0|\n",
      "|      10223|           37.0|    100.0|              1|3965.66| 2/20/2004 0:00|Shipped|     1|       2|   2004|Motorcycles|95.0|   S10_1678|Australian Collec...|    03 9520 4555|   636 St Kilda Road|     Level 3|    Melbourne|Victoria|      3004|Australia|     APAC|       Ferguson|           Peter|  Medium|            3700.0|\n",
      "|      10237|           23.0|    100.0|              7|2333.12|  4/5/2004 0:00|Shipped|     2|       4|   2004|Motorcycles|95.0|   S10_1678|     Vitachrome Inc.|      2125551500|   2678 Kingston Rd.|   Suite 101|          NYC|      NY|     10022|      USA|       NA|          Frick|         Michael|   Small|            2300.0|\n",
      "|      10251|           28.0|    100.0|              2|3188.64| 5/18/2004 0:00|Shipped|     2|       5|   2004|Motorcycles|95.0|   S10_1678|Tekni Collectable...|      2015559350|       7476 Moss Rd.|          NA|       Newark|      NJ|     94019|      USA|       NA|          Brown|         William|  Medium|            2800.0|\n",
      "|      10263|           34.0|    100.0|              2|3676.76| 6/28/2004 0:00|Shipped|     2|       6|   2004|Motorcycles|95.0|   S10_1678|     Gift Depot Inc.|      2035552570| 25593 South Bay Ln.|          NA|  Bridgewater|      CT|     97562|      USA|       NA|           King|           Julie|  Medium|            3400.0|\n",
      "|      10275|           45.0|    92.83|              1|4177.35| 7/23/2004 0:00|Shipped|     3|       7|   2004|Motorcycles|95.0|   S10_1678|   La Rochelle Gifts|      40.67.8555|67, rue des Cinqu...|          NA|       Nantes|      NA|     44000|   France|     EMEA|        Labrune|          Janine|  Medium|           4177.35|\n",
      "|      10285|           36.0|    100.0|              6|4099.68| 8/27/2004 0:00|Shipped|     3|       8|   2004|Motorcycles|95.0|   S10_1678|Marta's Replicas Co.|      6175558555| 39323 Spinnaker Dr.|          NA|    Cambridge|      MA|     51247|      USA|       NA|      Hernandez|           Marta|  Medium|            3600.0|\n",
      "|      10299|           23.0|    100.0|              9|2597.39| 9/30/2004 0:00|Shipped|     3|       9|   2004|Motorcycles|95.0|   S10_1678|Toys of Finland, Co.|     90-224 8555|       Keskuskatu 45|          NA|     Helsinki|      NA|     21240|  Finland|     EMEA|      Karttunen|           Matti|   Small|            2300.0|\n",
      "|      10309|           41.0|    100.0|              5|4394.38|10/15/2004 0:00|Shipped|     4|      10|   2004|Motorcycles|95.0|   S10_1678|  Baane Mini Imports|      07-98 9555|Erling Skakkes ga...|          NA|      Stavern|      NA|      4110|   Norway|     EMEA|     Bergulfsen|           Jonas|  Medium|            4100.0|\n",
      "|      10318|           46.0|    94.74|              1|4358.04| 11/2/2004 0:00|Shipped|     4|      11|   2004|Motorcycles|95.0|   S10_1678|Diecast Classics ...|      2155551555|    7586 Pompton St.|          NA|    Allentown|      PA|     70267|      USA|       NA|             Yu|           Kyung|  Medium|           4358.04|\n",
      "|      10329|           42.0|    100.0|              1|4396.14|11/15/2004 0:00|Shipped|     4|      11|   2004|Motorcycles|95.0|   S10_1678|   Land of Toys Inc.|      2125557818|897 Long Airport ...|          NA|          NYC|      NY|     10022|      USA|       NA|             Yu|            Kwai|  Medium|            4200.0|\n",
      "+-----------+---------------+---------+---------------+-------+---------------+-------+------+--------+-------+-----------+----+-----------+--------------------+----------------+--------------------+------------+-------------+--------+----------+---------+---------+---------------+----------------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def capp_outliers(df, column):\n",
    "    quantiles = df.approxQuantile(column, [0.25, 0.75], 0.0001)\n",
    "    Q1, Q3 = quantiles[0], quantiles[1]\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    count = df.filter((col(column) < lower_bound) | (col(column) > upper_bound)).count()\n",
    "    print(f\"{column}: {count}\")\n",
    "    capped_sales_data = df.withColumn(\n",
    "        column,\n",
    "        when(col(column) < lower_bound, lower_bound)\\\n",
    "        .when(col(column) > upper_bound, upper_bound)\\\n",
    "        .otherwise(col(column))\n",
    "    )\n",
    "    \n",
    "    return capped_sales_data\n",
    "\n",
    "capped_data = capp_outliers(cleaned_sales_data, \"SALES\")\n",
    "capped_data = capp_outliers(capped_data, \"MSRP\")\n",
    "capped_data = capp_outliers(capped_data, \"QUANTITYORDERED\")\n",
    "capped_data = capp_outliers(capped_data, \"PRICEEACH\")\n",
    "\n",
    "capped_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de98557a",
   "metadata": {},
   "source": [
    "### r) How would you cache a DataFrame containing sales data from the top 10 countries by sales to avoid recomputation in subsequent transformations? What persistence level (e.g. MEMORY_ONLY, MEMORY_AND_DISK) would you choose and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5eb3e2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2421"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "top_10_countries_df = cleaned_sales_data \\\n",
    "    .groupBy(\"COUNTRY\").agg(sum(\"SALES\").alias(\"TOTAL_SALES\")) \\\n",
    "    .orderBy(col(\"TOTAL_SALES\").desc()) \\\n",
    "    .limit(10) \\\n",
    "    .select([\"COUNTRY\", \"TOTAL_SALES\"])\n",
    "\n",
    "cached_df = cleaned_sales_data.join(top_10_countries_df, on=\"COUNTRY\", how=\"inner\")\n",
    "cached_df.persist(StorageLevel.MEMORY_ONLY)\n",
    "\n",
    "cached_df.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceb837f",
   "metadata": {},
   "source": [
    "- MEMORY ONLY Caches the data in memory(RAM) only\n",
    "- MEMORY_AND_DISK caches data in memory and disk\n",
    "- Since top 10 data is small memory only is sufficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4e0de2",
   "metadata": {},
   "source": [
    "### s) How would you pivot the data to show PRODUCTLINE as columns and the total SALES for each ORDERDATE as the values? What are the implications of pivoting large datasets in Spark?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36da4c7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+-----------+-------+-------+-------+----------------+------------+\n",
      "|     ORDERDATE|Classic Cars|Motorcycles| Planes|  Ships| Trains|Trucks and Buses|Vintage Cars|\n",
      "+--------------+------------+-----------+-------+-------+-------+----------------+------------+\n",
      "|3/29/2004 0:00|         0.0|        0.0|    0.0|2466.86|    0.0|             0.0|      3788.4|\n",
      "|5/30/2005 0:00|         0.0|        0.0|    0.0|    0.0|    0.0|             0.0|     2082.68|\n",
      "|3/19/2004 0:00|     7665.35|        0.0|    0.0|    0.0|    0.0|             0.0|         0.0|\n",
      "| 9/7/2004 0:00|         0.0|        0.0|    0.0|    0.0|    0.0|             0.0|     3836.69|\n",
      "| 5/4/2004 0:00|     5113.62|        0.0|    0.0|    0.0|    0.0|         3787.66|     2694.15|\n",
      "|11/9/2004 0:00|         0.0|        0.0|    0.0|3336.65|3807.68|             0.0|     3221.78|\n",
      "|11/4/2003 0:00|     3441.18|    3146.19|    0.0|    0.0|    0.0|             0.0|         0.0|\n",
      "| 7/1/2003 0:00|         0.0|     3660.7|    0.0|    0.0|    0.0|             0.0|         0.0|\n",
      "|12/1/2003 0:00|         0.0|    3633.13|3560.48|    0.0|    0.0|             0.0|      1113.6|\n",
      "| 7/2/2004 0:00|     6167.41|        0.0|    0.0|    0.0|    0.0|             0.0|         0.0|\n",
      "|1/29/2003 0:00|      5087.9|        0.0|    0.0|    0.0|    0.0|         3291.59|     2732.87|\n",
      "| 9/3/2003 0:00|     4444.54|    3155.58|    0.0|    0.0|    0.0|             0.0|         0.0|\n",
      "|3/23/2005 0:00|     6109.29|        0.0|    0.0|4160.44| 2154.0|             0.0|     3902.65|\n",
      "|10/4/2003 0:00|     3407.22|        0.0|    0.0|    0.0|    0.0|             0.0|         0.0|\n",
      "|7/24/2003 0:00|     4892.34|        0.0|    0.0|    0.0|    0.0|         3728.57|     1254.83|\n",
      "| 3/3/2003 0:00|     3873.26|    2527.83|    0.0|    0.0|    0.0|             0.0|         0.0|\n",
      "|1/23/2005 0:00|     3308.46|        0.0|    0.0|    0.0| 2986.5|         2657.41|         0.0|\n",
      "|4/26/2004 0:00|         0.0|        0.0|    0.0|    0.0|    0.0|             0.0|      3564.5|\n",
      "|2/16/2005 0:00|      3059.4|        0.0|    0.0|    0.0|    0.0|             0.0|     2857.71|\n",
      "|4/21/2003 0:00|         0.0|        0.0|    0.0| 4219.2|    0.0|             0.0|         0.0|\n",
      "+--------------+------------+-----------+-------+-------+-------+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, round\n",
    "\n",
    "pivoted_df = cleaned_sales_data.groupBy(\"ORDERDATE\").pivot(\"PRODUCTLINE\").agg(round(avg(\"SALES\"), 2))\n",
    "pivoted_df = pivoted_df.fillna(0)\n",
    "pivoted_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe85b81",
   "metadata": {},
   "source": [
    "if the data is very large pivot data may take huge amount of memory and time due to shuffling of data. \n",
    "If the dataset is large and the data is not evenly distributed, it may cause incosistancies in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1494d474",
   "metadata": {},
   "source": [
    "### t) How would you calculate the percentage growth of total sales month over month for each PRODUCTLINE using Spark DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad7362e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------+------------------+------------------+-------------------+\n",
      "|PRODUCTLINE|YEAR_ID|MONTH_ID|       TOTAL_SALES|  PREV_TOTAL_SALES|  PERCENTAGE_GROWTH|\n",
      "+-----------+-------+--------+------------------+------------------+-------------------+\n",
      "|Motorcycles|   2003|       2|25783.760000000002|              null|               null|\n",
      "|Motorcycles|   2003|       3|          12639.15|25783.760000000002| -50.98019063162239|\n",
      "|Motorcycles|   2003|       4|23475.590000000004|          12639.15|   85.7370946622202|\n",
      "|Motorcycles|   2003|       5|          22097.32|23475.590000000004|-5.8710771486467594|\n",
      "|Motorcycles|   2003|       6|           2642.01|          22097.32| -88.04375372217082|\n",
      "|Motorcycles|   2003|       7| 37924.23000000001|           2642.01|  1335.430978686682|\n",
      "|Motorcycles|   2003|       8|44164.909999999996| 37924.23000000001| 16.455653812878953|\n",
      "|Motorcycles|   2003|       9|           3155.58|44164.909999999996| -92.85500638402749|\n",
      "|Motorcycles|   2003|      10| 64235.65000000001|           3155.58| 1935.6210268793695|\n",
      "|Motorcycles|   2003|      11|          109345.5| 64235.65000000001|  70.22556788948191|\n",
      "|Motorcycles|   2003|      12|25431.879999999997|          109345.5| -76.74172233882508|\n",
      "|Motorcycles|   2004|       1|          41200.52|25431.879999999997|  62.00343820433252|\n",
      "|Motorcycles|   2004|       2|           49066.5|          41200.52| 19.091943499742246|\n",
      "|Motorcycles|   2004|       4| 36269.07000000001|           49066.5| -26.08180734309558|\n",
      "|Motorcycles|   2004|       5|46848.950000000004| 36269.07000000001|  29.17053015144859|\n",
      "|Motorcycles|   2004|       6|          47237.41|46848.950000000004| 0.8291754671129217|\n",
      "|Motorcycles|   2004|       7|           22774.0|          47237.41|-51.788211927791984|\n",
      "|Motorcycles|   2004|       8|          62704.93|           22774.0|  175.3356020022833|\n",
      "|Motorcycles|   2004|       9| 42471.04999999999|          62704.93| -32.26840377622623|\n",
      "|Motorcycles|   2004|      10|          39413.96| 42471.04999999999|-7.1980560876173065|\n",
      "+-----------+-------+--------+------------------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum, lag, col, coalesce, lit\n",
    "\n",
    "monthly_sales = cleaned_sales_data.groupBy(\"PRODUCTLINE\", \"YEAR_ID\", \"MONTH_ID\") \\\n",
    "                                   .agg(sum(\"SALES\").alias(\"TOTAL_SALES\"))\n",
    "\n",
    "window= Window.partitionBy(\"PRODUCTLINE\").orderBy(\"YEAR_ID\", \"MONTH_ID\")\n",
    "\n",
    "monthly_sales_with_prev = monthly_sales.withColumn(\"PREV_TOTAL_SALES\", lag(\"TOTAL_SALES\").over(window))\n",
    "\n",
    "monthly_sales_with_growth = monthly_sales_with_prev.withColumn(\n",
    "    \"PERCENTAGE_GROWTH\",\n",
    "    (col(\"TOTAL_SALES\") - coalesce(col(\"PREV_TOTAL_SALES\"), lit(0))) /\n",
    "    coalesce(col(\"PREV_TOTAL_SALES\"), lit(0)) * 100\n",
    ")\n",
    "\n",
    "monthly_sales_with_growth.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e53b58",
   "metadata": {},
   "source": [
    "### u) How can you rebalance the data by portioning based on the COUNTRY column to ensure that large data partitions are avoided?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b657a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_sales_data.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "031b8f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_sales_data.select(\"COUNTRY\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea3889fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Partition by each country\n",
    "cleaned_sales_data.repartition(19,\"COUNTRY\").rdd.getNumPartitions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044b64cb",
   "metadata": {},
   "source": [
    "### v) Suppose you have a smaller lookup table with customer details. How would you perform a broadcast join with the large sales_data_sample dataset to improve join performance? What are the key considerations when using broadcast joins?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1939b8e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+--------------------+\n",
      "|ORDERNUMBER|      CUSTOMERNAME|      customer_email|\n",
      "+-----------+------------------+--------------------+\n",
      "|      10107| Land of Toys Inc.|landoftoys@exampl...|\n",
      "|      10121|Reims Collectables|reims.co@example.com|\n",
      "|      10329| Land of Toys Inc.|landoftoys@exampl...|\n",
      "|      10107| Land of Toys Inc.|landoftoys@exampl...|\n",
      "|      10329| Land of Toys Inc.|landoftoys@exampl...|\n",
      "|      10107| Land of Toys Inc.|landoftoys@exampl...|\n",
      "|      10329| Land of Toys Inc.|landoftoys@exampl...|\n",
      "|      10248| Land of Toys Inc.|landoftoys@exampl...|\n",
      "|      10359|Reims Collectables|reims.co@example.com|\n",
      "|      10329| Land of Toys Inc.|landoftoys@exampl...|\n",
      "|      10359|Reims Collectables|reims.co@example.com|\n",
      "|      10107| Land of Toys Inc.|landoftoys@exampl...|\n",
      "|      10121|Reims Collectables|reims.co@example.com|\n",
      "|      10329| Land of Toys Inc.|landoftoys@exampl...|\n",
      "|      10329| Land of Toys Inc.|landoftoys@exampl...|\n",
      "|      10359|Reims Collectables|reims.co@example.com|\n",
      "|      10329| Land of Toys Inc.|landoftoys@exampl...|\n",
      "|      10292| Land of Toys Inc.|landoftoys@exampl...|\n",
      "|      10329| Land of Toys Inc.|landoftoys@exampl...|\n",
      "|      10137|Reims Collectables|reims.co@example.com|\n",
      "+-----------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "customer_details = spark.createDataFrame([\n",
    "    (1, \"Land of Toys Inc.\", \"landoftoys@example.com\"),\n",
    "    (2, \"Reims Collectables\", \"reims.co@example.com\")\n",
    "], [\"customer_id\", \"customer_name\", \"customer_email\"])\n",
    "\n",
    "broadcast_df = broadcast(customer_details)\n",
    "\n",
    "cleaned_sales_data = cleaned_sales_data.cache()\n",
    "\n",
    "joined_df = cleaned_sales_data.join(\n",
    "    broadcast_df,\n",
    "    cleaned_sales_data[\"CUSTOMERNAME\"] == customer_details[\"customer_name\"],\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "joined_df.select([\"ORDERNUMBER\", \"CUSTOMERNAME\", \"customer_email\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afde481",
   "metadata": {},
   "source": [
    "- data is send to all worker nodes, reduced number of shuffling\n",
    "- considerations:\n",
    "    - when one data in significantly smaller than the other one, broadcast join will be ideal\n",
    "    - small data will be distributed among all worker nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c20a151",
   "metadata": {},
   "source": [
    "### w) Create a UDF that categorizes the sales values (SALES) into custom buckets like Low, Medium, High. Apply this UDF to the DataFrame and calculate the count of orders in each category per COUNTRY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d89d2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "def categorize_sales(sales_amount):\n",
    "    if sales_amount > percentile_67:\n",
    "        return \"High\"\n",
    "    elif sales_amount > percentile_33:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "    \n",
    "categorize_sales_udf = udf(categorize_sales, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6982bf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|  SALES|SALES_CATEGORY|\n",
      "+-------+--------------+\n",
      "| 2871.0|        Medium|\n",
      "| 2765.9|        Medium|\n",
      "|3884.34|        Medium|\n",
      "| 3746.7|        Medium|\n",
      "|5205.27|          High|\n",
      "|3479.76|        Medium|\n",
      "|2497.77|        Medium|\n",
      "|5512.32|          High|\n",
      "|2168.54|           Low|\n",
      "|4708.44|          High|\n",
      "|3965.66|          High|\n",
      "|2333.12|           Low|\n",
      "|3188.64|        Medium|\n",
      "|3676.76|        Medium|\n",
      "|4177.35|          High|\n",
      "|4099.68|          High|\n",
      "|2597.39|        Medium|\n",
      "|4394.38|          High|\n",
      "|4358.04|          High|\n",
      "|4396.14|          High|\n",
      "+-------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_data_with_category = cleaned_sales_data.withColumn(\n",
    "    \"SALES_CATEGORY\", categorize_sales_udf(col(\"SALES\"))\n",
    ")\n",
    "\n",
    "sales_data_with_category.select(['SALES','SALES_CATEGORY']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c862b07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-----+\n",
      "|  COUNTRY|SALES_CATEGORY|count|\n",
      "+---------+--------------+-----+\n",
      "|Australia|          High|   60|\n",
      "|Australia|           Low|   66|\n",
      "|Australia|        Medium|   59|\n",
      "|  Austria|          High|   20|\n",
      "|  Austria|           Low|   15|\n",
      "|  Austria|        Medium|   20|\n",
      "|  Belgium|          High|   11|\n",
      "|  Belgium|           Low|   14|\n",
      "|  Belgium|        Medium|    8|\n",
      "|   Canada|          High|   18|\n",
      "|   Canada|           Low|   28|\n",
      "|   Canada|        Medium|   24|\n",
      "|  Denmark|          High|   23|\n",
      "|  Denmark|           Low|   18|\n",
      "|  Denmark|        Medium|   22|\n",
      "|  Finland|          High|   32|\n",
      "|  Finland|           Low|   24|\n",
      "|  Finland|        Medium|   36|\n",
      "|   France|          High|  101|\n",
      "|   France|           Low|  110|\n",
      "+---------+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_counts_per_country = sales_data_with_category.groupBy(\"COUNTRY\", \"SALES_CATEGORY\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"COUNTRY\", \"SALES_CATEGORY\")\n",
    "\n",
    "sales_counts_per_country.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f46c48",
   "metadata": {},
   "source": [
    "### x) Create a Python UDF to calculate discounts for specific product lines. For example, give a 10% discount for Classic Cars and 5% for Motorcycles. Apply this UDF to derive new discounted sales values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c76daee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+---------+---------------+-------+---------------+-------+------+--------+-------+-----------+----+-----------+--------------------+----------------+--------------------+------------+-------------+--------+----------+---------+---------+---------------+----------------+--------+------------------+------------------+\n",
      "|ORDERNUMBER|QUANTITYORDERED|PRICEEACH|ORDERLINENUMBER|  SALES|      ORDERDATE| STATUS|QTR_ID|MONTH_ID|YEAR_ID|PRODUCTLINE|MSRP|PRODUCTCODE|        CUSTOMERNAME|           PHONE|        ADDRESSLINE1|ADDRESSLINE2|         CITY|   STATE|POSTALCODE|  COUNTRY|TERRITORY|CONTACTLASTNAME|CONTACTFIRSTNAME|DEALSIZE|     TOTAL_REVENUE|  DISCOUNTED_SALES|\n",
      "+-----------+---------------+---------+---------------+-------+---------------+-------+------+--------+-------+-----------+----+-----------+--------------------+----------------+--------------------+------------+-------------+--------+----------+---------+---------+---------------+----------------+--------+------------------+------------------+\n",
      "|      10107|             30|     95.7|              2| 2871.0| 2/24/2003 0:00|Shipped|     1|       2|   2003|Motorcycles|  95|   S10_1678|   Land of Toys Inc.|      2125557818|897 Long Airport ...|          NA|          NYC|      NY|     10022|      USA|       NA|             Yu|            Kwai|   Small|            2871.0|           2727.45|\n",
      "|      10121|             34|    81.35|              5| 2765.9|  5/7/2003 0:00|Shipped|     2|       5|   2003|Motorcycles|  95|   S10_1678|  Reims Collectables|      26.47.1555|  59 rue de l'Abbaye|          NA|        Reims|      NA|     51100|   France|     EMEA|        Henriot|            Paul|   Small|2765.8999999999996|          2627.605|\n",
      "|      10134|             41|    94.74|              2|3884.34|  7/1/2003 0:00|Shipped|     3|       7|   2003|Motorcycles|  95|   S10_1678|     Lyon Souveniers|+33 1 46 62 7555|27 rue du Colonel...|          NA|        Paris|      NA|     75508|   France|     EMEA|       Da Cunha|          Daniel|  Medium|3884.3399999999997|          3690.123|\n",
      "|      10145|             45|    83.26|              6| 3746.7| 8/25/2003 0:00|Shipped|     3|       8|   2003|Motorcycles|  95|   S10_1678|   Toys4GrownUps.com|      6265557265|  78934 Hillside Dr.|          NA|     Pasadena|      CA|     90003|      USA|       NA|          Young|           Julie|  Medium|3746.7000000000003|          3559.365|\n",
      "|      10159|             49|    100.0|             14|5205.27|10/10/2003 0:00|Shipped|     4|      10|   2003|Motorcycles|  95|   S10_1678|Corporate Gift Id...|      6505551386|     7734 Strong St.|          NA|San Francisco|      CA|        NA|      USA|       NA|          Brown|           Julie|  Medium|            4900.0|         4945.0065|\n",
      "|      10168|             36|    96.66|              1|3479.76|10/28/2003 0:00|Shipped|     4|      10|   2003|Motorcycles|  95|   S10_1678|Technics Stores Inc.|      6505556809|   9408 Furth Circle|          NA|   Burlingame|      CA|     94217|      USA|       NA|         Hirano|            Juri|  Medium|3479.7599999999998|          3305.772|\n",
      "|      10180|             29|    86.13|              9|2497.77|11/11/2003 0:00|Shipped|     4|      11|   2003|Motorcycles|  95|   S10_1678|Daedalus Designs ...|      20.16.1555|184, chausse de T...|          NA|        Lille|      NA|     59000|   France|     EMEA|          Rance|         Martine|   Small|           2497.77|         2372.8815|\n",
      "|      10188|             48|    100.0|              1|5512.32|11/18/2003 0:00|Shipped|     4|      11|   2003|Motorcycles|  95|   S10_1678|        Herkku Gifts|   +47 2267 3215|Drammen 121, PR 7...|          NA|       Bergen|      NA|    N 5804|   Norway|     EMEA|         Oeztan|          Veysel|  Medium|            4800.0|          5236.704|\n",
      "|      10201|             22|    98.57|              2|2168.54| 12/1/2003 0:00|Shipped|     4|      12|   2003|Motorcycles|  95|   S10_1678|     Mini Wheels Co.|      6505555787|5557 North Pendal...|          NA|San Francisco|      CA|        NA|      USA|       NA|         Murphy|           Julie|   Small|           2168.54|          2060.113|\n",
      "|      10211|             41|    100.0|             14|4708.44| 1/15/2004 0:00|Shipped|     1|       1|   2004|Motorcycles|  95|   S10_1678|    Auto Canal Petit|  (1) 47.55.6555|   25, rue Lauriston|          NA|        Paris|      NA|     75016|   France|     EMEA|        Perrier|       Dominique|  Medium|            4100.0| 4473.017999999999|\n",
      "|      10223|             37|    100.0|              1|3965.66| 2/20/2004 0:00|Shipped|     1|       2|   2004|Motorcycles|  95|   S10_1678|Australian Collec...|    03 9520 4555|   636 St Kilda Road|     Level 3|    Melbourne|Victoria|      3004|Australia|     APAC|       Ferguson|           Peter|  Medium|            3700.0|3767.3769999999995|\n",
      "|      10237|             23|    100.0|              7|2333.12|  4/5/2004 0:00|Shipped|     2|       4|   2004|Motorcycles|  95|   S10_1678|     Vitachrome Inc.|      2125551500|   2678 Kingston Rd.|   Suite 101|          NYC|      NY|     10022|      USA|       NA|          Frick|         Michael|   Small|            2300.0|          2216.464|\n",
      "|      10251|             28|    100.0|              2|3188.64| 5/18/2004 0:00|Shipped|     2|       5|   2004|Motorcycles|  95|   S10_1678|Tekni Collectable...|      2015559350|       7476 Moss Rd.|          NA|       Newark|      NJ|     94019|      USA|       NA|          Brown|         William|  Medium|            2800.0|3029.2079999999996|\n",
      "|      10263|             34|    100.0|              2|3676.76| 6/28/2004 0:00|Shipped|     2|       6|   2004|Motorcycles|  95|   S10_1678|     Gift Depot Inc.|      2035552570| 25593 South Bay Ln.|          NA|  Bridgewater|      CT|     97562|      USA|       NA|           King|           Julie|  Medium|            3400.0|          3492.922|\n",
      "|      10275|             45|    92.83|              1|4177.35| 7/23/2004 0:00|Shipped|     3|       7|   2004|Motorcycles|  95|   S10_1678|   La Rochelle Gifts|      40.67.8555|67, rue des Cinqu...|          NA|       Nantes|      NA|     44000|   France|     EMEA|        Labrune|          Janine|  Medium|           4177.35|         3968.4825|\n",
      "|      10285|             36|    100.0|              6|4099.68| 8/27/2004 0:00|Shipped|     3|       8|   2004|Motorcycles|  95|   S10_1678|Marta's Replicas Co.|      6175558555| 39323 Spinnaker Dr.|          NA|    Cambridge|      MA|     51247|      USA|       NA|      Hernandez|           Marta|  Medium|            3600.0|          3894.696|\n",
      "|      10299|             23|    100.0|              9|2597.39| 9/30/2004 0:00|Shipped|     3|       9|   2004|Motorcycles|  95|   S10_1678|Toys of Finland, Co.|     90-224 8555|       Keskuskatu 45|          NA|     Helsinki|      NA|     21240|  Finland|     EMEA|      Karttunen|           Matti|   Small|            2300.0|2467.5204999999996|\n",
      "|      10309|             41|    100.0|              5|4394.38|10/15/2004 0:00|Shipped|     4|      10|   2004|Motorcycles|  95|   S10_1678|  Baane Mini Imports|      07-98 9555|Erling Skakkes ga...|          NA|      Stavern|      NA|      4110|   Norway|     EMEA|     Bergulfsen|           Jonas|  Medium|            4100.0|          4174.661|\n",
      "|      10318|             46|    94.74|              1|4358.04| 11/2/2004 0:00|Shipped|     4|      11|   2004|Motorcycles|  95|   S10_1678|Diecast Classics ...|      2155551555|    7586 Pompton St.|          NA|    Allentown|      PA|     70267|      USA|       NA|             Yu|           Kyung|  Medium|           4358.04|          4140.138|\n",
      "|      10329|             42|    100.0|              1|4396.14|11/15/2004 0:00|Shipped|     4|      11|   2004|Motorcycles|  95|   S10_1678|   Land of Toys Inc.|      2125557818|897 Long Airport ...|          NA|          NYC|      NY|     10022|      USA|       NA|             Yu|            Kwai|  Medium|            4200.0|4176.3330000000005|\n",
      "+-----------+---------------+---------+---------------+-------+---------------+-------+------+--------+-------+-----------+----+-----------+--------------------+----------------+--------------------+------------+-------------+--------+----------+---------+---------+---------------+----------------+--------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def apply_discount(product_line, sales_amount):\n",
    "    if product_line == \"Classic Cars\":\n",
    "        return sales_amount * 0.90  \n",
    "    elif product_line == \"Motorcycles\":\n",
    "        return sales_amount * 0.95 \n",
    "    else:\n",
    "        return sales_amount \n",
    "\n",
    "apply_discount_udf = udf(apply_discount, DoubleType())\n",
    "\n",
    "sales_data_with_discount = cleaned_sales_data.withColumn(\n",
    "    \"DISCOUNTED_SALES\", apply_discount_udf(col(\"PRODUCTLINE\"), col(\"SALES\"))\n",
    ")\n",
    "\n",
    "sales_data_with_discount.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20d2755",
   "metadata": {},
   "source": [
    "### y) How would you set up an incremental loading mechanism for orders placed daily based on the ORDERDATE column? How can Spark checkpointing can be used with incremental load to ensure no data loss occurs during failures?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7c2041",
   "metadata": {},
   "source": [
    "### z) How do you implement a cumulative distribution function (CDF) over the SALES value for each CUSTOMERNAME? What insights can you gather from analyzing the CDF distribution for each customer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30292c13",
   "metadata": {},
   "source": [
    "same as n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
